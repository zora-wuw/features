{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ip = config['DEFAULT']['IP']\n",
    "port = config['DEFAULT']['MongoDB-Port']\n",
    "contain_string = config['DEFAULT']['Contain-String']\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(ip, int(port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database and get collections' names\n",
    "db_twitter = client[\"Twitter\"]\n",
    "collections_twitter = db_twitter.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current year : 2019\n",
      "current week : 18\n"
     ]
    }
   ],
   "source": [
    "# get current year and current week number\n",
    "current_timestamp = int(time.time() * 1000)\n",
    "current_year = int(datetime.datetime.now().year)\n",
    "print(\"current year : \" + str(current_year))\n",
    "\n",
    "current_week = int((current_timestamp - 1546214400000)/1000/604800)+1\n",
    "print(\"current week : \" + str(current_week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_W1_Twitter_Australia: 40880\n"
     ]
    }
   ],
   "source": [
    "# list all collection and the number of records in each collection\n",
    "dic_collection = {}\n",
    "for i in collections_twitter:\n",
    "    if i.startswith(\"20\") and contain_string in i:\n",
    "        year = i[0:4]\n",
    "        week = re.search('_(.+?)_', i).group(1)[1:]\n",
    "        if int(year) < current_year:\n",
    "            dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "        else:\n",
    "            try:\n",
    "                if int(week) < current_week:\n",
    "                    dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "            except: pass\n",
    "\n",
    "for key in sorted(dic_collection):\n",
    "    print(\"%s: %s\" % (key, dic_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. create csv for each collection based on hashtag and user location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write into csv file\n",
    "def write_csv(file_name,hashtag,user_location):\n",
    "    # avoid user location splitted by comma\n",
    "    try:\n",
    "        user_location = ''.join(user_location.split(','))\n",
    "    except:\n",
    "        pass\n",
    "    row = \"{},{}\\n\".format(hashtag,user_location)\n",
    "    \n",
    "    with open(file_name, 'a') as f:      \n",
    "        f.write(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate running time\n",
    "def calculate_time(start_time, t):\n",
    "    current_time = time.time()\n",
    "    duration = current_time - start_time\n",
    "    if (duration/60) >= (t+10):\n",
    "        t += 10\n",
    "        print(\"The program is still running, already run for about \"+ str(t) + \" minutes.\")\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create foler if not exist\n",
    "def create_folder():\n",
    "    folder = \"output/hashtag_user_location/\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existed collection from the list dic_collection\n",
    "def delete_collection(folder,dic_collection):\n",
    "    for input_file in glob.glob(os.path.join(folder,'*.csv')):\n",
    "        collection_name = re.search('_location/(.+?)_hashtag', input_file).group(1)\n",
    "        print(\"Existed collection: \" + collection_name)\n",
    "        if collection_name in dic_collection:\n",
    "            del dic_collection[collection_name]\n",
    "    return dic_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed collection: 2019_W1_Twitter_Australia\n"
     ]
    }
   ],
   "source": [
    "#create folder if not exist\n",
    "folder = create_folder()\n",
    "dic_collection = delete_collection(folder,dic_collection)\n",
    "for collection in sorted(dic_collection):\n",
    "    \n",
    "    print(\"-----------------------\")\n",
    "    print(\"processing on collection \" + str(collection))\n",
    "    start = time. time()\n",
    "    t =0\n",
    "\n",
    "    file_name = folder + str(collection) + \"_hashtag_user_location.csv\"\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write('hashtag,user_location\\n')\n",
    "\n",
    "    for document in db_twitter[collection].find():\n",
    "\n",
    "        # twitter_id = document['id']\n",
    "        user_location = document['user']['location']\n",
    "\n",
    "        if len(document['entities']['hashtags']) == 0:\n",
    "            hashtag = None\n",
    "            write_csv(file_name,hashtag,user_location)\n",
    "            t = calculate_time(start, t)\n",
    "        elif len(document['entities']['hashtags']) == 1:\n",
    "            hashtag = document['entities']['hashtags'][0]['text']\n",
    "            write_csv(file_name,hashtag,user_location)\n",
    "            t = calculate_time(start, t)\n",
    "        else:\n",
    "            for i in range(len(document['entities']['hashtags'])):\n",
    "                hashtag = document['entities']['hashtags'][i]['text']\n",
    "                write_csv(file_name,hashtag,user_location)\n",
    "                t = calculate_time(start, t)\n",
    "\n",
    "    print(\"csv file for collection \" + collection + \" is done.\")\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
