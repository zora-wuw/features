{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import pandas\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import configparser \n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ip = config['DEFAULT']['IP']\n",
    "port = config['DEFAULT']['MongoDB-Port']\n",
    "contain_string = config['DEFAULT']['Contain-String']\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(ip, int(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_twitter = client[\"Twitter\"]\n",
    "collections_twitter = db_twitter.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current year : 2019\n",
      "current week : 14\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = int(time.time() * 1000)\n",
    "current_year = int(datetime.datetime.now().year)\n",
    "print(\"current year : \" + str(current_year))\n",
    "\n",
    "current_week = int((current_timestamp - 1546214400000)/1000/604800)+1\n",
    "print(\"current week : \" + str(current_week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_W51_Twitter_Australia: 20471\n",
      "2018_W51_Twitter_Other: 8978243\n",
      "2018_W52_Twitter_Australia: 38065\n",
      "2018_W52_Twitter_Other: 16940708\n",
      "2019_W01_Twitter_Australia: 40880\n",
      "2019_W01_Twitter_Other: 16994959\n",
      "2019_W02_Twitter_Australia: 37645\n",
      "2019_W02_Twitter_Other: 14474627\n",
      "2019_W03_Twitter_Australia: 52348\n",
      "2019_W03_Twitter_Other: 20416992\n",
      "2019_W04_Twitter_Australia: 59625\n",
      "2019_W04_Twitter_Other: 23417927\n",
      "2019_W05_Twitter_Australia: 61617\n",
      "2019_W05_Twitter_Other: 23917345\n",
      "2019_W06_Twitter_Australia: 61435\n",
      "2019_W06_Twitter_Other: 24176122\n",
      "2019_W07_Twitter_Australia: 28017\n",
      "2019_W07_Twitter_Other: 10484648\n",
      "2019_W08_Twitter_Australia: 60035\n",
      "2019_W08_Twitter_Other: 23446630\n",
      "2019_W09_Twitter_Australia: 58316\n",
      "2019_W09_Twitter_Other: 22293795\n",
      "2019_W10_Twitter_Australia: 40767\n",
      "2019_W10_Twitter_Other: 15941350\n",
      "2019_W11_Twitter_Australia: 68593\n",
      "2019_W11_Twitter_Other: 25345811\n",
      "2019_W12_Twitter_Australia: 50447\n",
      "2019_W12_Twitter_Other: 18090490\n",
      "2019_W13_Twitter_Australia: 62926\n",
      "2019_W13_Twitter_Other: 24379236\n"
     ]
    }
   ],
   "source": [
    "dic_collection = {}\n",
    "for i in collections_twitter:\n",
    "    #if i.startswith(\"20\") and \"Australia\" in i:\n",
    "    if i.startswith(\"20\") and contain_string in i:\n",
    "        year = i[0:4]\n",
    "        week = re.search('_(.+?)_', i).group(1)[1:]\n",
    "        if int(year) < current_year:\n",
    "            dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "        else:\n",
    "            try:\n",
    "                if int(week) < current_week:\n",
    "                    dic_collection[i] = \"{:}\".format(db_twitter[i].find({}).count())\n",
    "            except: pass\n",
    "\n",
    "for key in sorted(dic_collection):\n",
    "    print(\"%s: %s\" % (key, dic_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce links between #tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$match\": { \"entities.hashtags\": {\"$exists\":True,\"$ne\":[]}}},\n",
    "    {\"$match\": { \"lang\" : \"en\"}},\n",
    "    { \"$group\": {\n",
    "        \"_id\": {\n",
    "            \"hashtags\": \"$entities.hashtags\"\n",
    "        },\n",
    "        \"count\": { \"$sum\": 1 },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create foler if not exist\n",
    "def create_folder():\n",
    "    folder = \"output/links_hashtags/\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete existed collection from the list dic_collection\n",
    "def delete_collection(folder,dic_collection):\n",
    "    for input_file in glob.glob(os.path.join(folder,'*.csv')):\n",
    "        collection_name = re.search('{(.+?)}', input_file).group(1)\n",
    "        if collection_name in dic_collection:\n",
    "            print(\"Existed collection: \" + collection_name)\n",
    "            del dic_collection[collection_name]\n",
    "    return dic_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to dictionary\n",
    "def append_dic(data_format,exist,dic):\n",
    "    data_format.append(dic)\n",
    "    exist = 1\n",
    "    return data_format,exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort hashtag\n",
    "def sort_hashtag(text1, text2):\n",
    "    l = [text1,text2]\n",
    "    sort_l = sorted(l)\n",
    "    return sort_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for the loop\n",
    "def floop(length,hashtags,data_format,text1):\n",
    "    for j in range(1,length):\n",
    "        exist = 0\n",
    "        # get hashtag2\n",
    "        text2 = hashtags[j][\"text\"].lower()\n",
    "        if(re.match(\"^[a-zA-Z0-9]*$\",text2)):\n",
    "            sort_l = sort_hashtag(text1, text2)\n",
    "            text1 = sort_l[0]\n",
    "            text2 = sort_l[1]\n",
    "            dic = {\"hashtags\": text1+ \",\" + text2, \"count\" : count}\n",
    "\n",
    "            if len(data_format) > 0 :\n",
    "                for d in data_format:\n",
    "                    if (text1 in d[\"hashtags\"]) and (text2 in d[\"hashtags\"]):\n",
    "                        d[\"count\"] += count\n",
    "                        exist = 1\n",
    "                if exist == 0:\n",
    "                    data_format,exist = append_dic(data_format,exist,dic)\n",
    "            else:        \n",
    "                data_format,exist = append_dic(data_format,exist,dic)\n",
    "    return data_format, exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv file\n",
    "def write_csv(collection,data_format):\n",
    "    \n",
    "    file_name = \"output/links_hashtags/{\" + collection + \"}_links_hashtags.csv\"\n",
    "    with open(file_name, 'w') as f:\n",
    "        # header\n",
    "        f.write('hashtag,linked_hashtag,number\\n')\n",
    "\n",
    "        for data in data_format:\n",
    "            hashtag1 = data['hashtags'].split(\",\")[0]\n",
    "            hashtag2 = data['hashtags'].split(\",\")[1]\n",
    "\n",
    "            line = hashtag1 + ',' + hashtag2 + ',' + str(data[\"count\"]) + '\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder if not exist\n",
    "folder = create_folder()\n",
    "    \n",
    "# delete existed collection from the list dic_collection\n",
    "dic_collection = delete_collection(folder,dic_collection)\n",
    "       \n",
    "for collection in sorted(dic_collection):\n",
    "    print(\"-----------------------\\n\")\n",
    "    print(\"Processing on collection: \" + collection)\n",
    "    \n",
    "    data_format = []\n",
    "    data_list = list(db_twitter[collection].aggregate(pipeline,allowDiskUse=True))\n",
    "\n",
    "    if len(data_list) > 0:\n",
    "        for data in data_list:\n",
    "            hashtags = data[\"_id\"][\"hashtags\"]\n",
    "            count = data[\"count\"]\n",
    "            length = len(hashtags)\n",
    "            if length > 1 :\n",
    "                for i in range(0,length-1):\n",
    "                    # get hashtag1\n",
    "                    text1 = hashtags[i][\"text\"].lower()\n",
    "                    # check if it is in English\n",
    "                    if(re.match(\"^[a-zA-Z0-9]*$\",text1)):\n",
    "                        data_format, exist = floop(length,hashtags,data_format,text1)\n",
    "            else: pass\n",
    "\n",
    "    print(\"linked hashtag list is finished\")   \n",
    "    \n",
    "    write_csv(collection,data_format)\n",
    "\n",
    "    print (\"linked hashtag csv file for collection \" + collection + ' is finished.')\n",
    "    print(\"-----------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
